# HGB

研究自己的工作更要细心了！

* 首先，回顾一下三个任务的代码，并且理解透彻每一个任务的评测指标。
* 其次，调研一下最新的工作。
* 最后，完善一下代码，包括数据的公开和下载脚本。

## 相关工作

### 同构

频域和空域的方法。

#### 频域

ChebNet

GCN

SGC

GWNN

#### 空域

空域主要包括：

* 聚合方式的不同设计：注意力、GIN
* 适应大图的inductive：GraphSAGE、FastGCN
* 正则化：GRAND、DropEdge、GCNII

GAT

GraphSAGE

FastGCN

DropEdge：我觉得没回答我最关心的几个问题

* 训练的时候如何保证scale的期望不变？（这就涉及到dropout的操作了）
* 预测的时候是否还drop？
* GCN可以用规范化，GAT怎么办？
* 对称地采样吗？双向边都drop？

这篇文章太不优雅了……明明是有偏的硬要说无偏，如果只是单纯求均值确实是无偏的，所以GAT和均值GCN可以，但是对称规范化的GCN就不行了。

而且结论居然就是直接随机drop边，相当于丢掉了图的信息啊……这算什么解决方案。


还可以写什么？数据格式、代码结构（包括数据格式的转化、simple-hgn代码的实现、数据加载和处理的方式、评测指标）、补充实验。

现在代码完全不用改了！写论文！把剩下的6页凑出来！！！

simple-hgn还是单独列一章，补充一下各种框架的代码实现，包括dgl、pyg、cogdl。正好顺便介绍一下各个框架。

我觉得还可以写一写有关链接预测测试集选择、负样本选择的问题。


